# ðŸš€ Production-Grade Azure ETL Pipeline for Data Transformation & Cleansing

## Overview
This project provides a complete production-ready ETL pipeline solution in Azure for data transformation and cleansing. It includes Infrastructure as Code (Terraform), Azure Data Factory pipelines, Databricks notebooks, and comprehensive monitoring.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Data      â”‚    â”‚   Staging Zone   â”‚    â”‚  Curated Zone   â”‚
â”‚   (ADLS Gen2)   â”‚â”€â”€â”€â–¶â”‚   (ADLS Gen2)    â”‚â”€â”€â”€â–¶â”‚   (ADLS Gen2)   â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ CSV files     â”‚    â”‚ â€¢ Validated      â”‚    â”‚ â€¢ Parquet       â”‚
â”‚ â€¢ JSON files    â”‚    â”‚ â€¢ Profiled       â”‚    â”‚ â€¢ Partitioned   â”‚
â”‚ â€¢ Parquet files â”‚    â”‚ â€¢ Cleaned        â”‚    â”‚ â€¢ Optimized     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Azure Data     â”‚    â”‚   Azure          â”‚    â”‚  Azure SQL      â”‚
â”‚  Factory        â”‚    â”‚  Databricks      â”‚    â”‚  Database       â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ Orchestration â”‚    â”‚ â€¢ Transformationsâ”‚    â”‚ â€¢ Final Tables  â”‚
â”‚ â€¢ Scheduling    â”‚    â”‚ â€¢ Data Quality   â”‚    â”‚ â€¢ Reporting     â”‚
â”‚ â€¢ Monitoring    â”‚    â”‚ â€¢ PII Masking    â”‚    â”‚ â€¢ Analytics     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Components

### 1. Infrastructure (Terraform)
- **Location**: `terraform/`
- Azure Data Lake Storage Gen2 (Raw, Staging, Curated zones)
- Azure Data Factory with managed identity
- Azure Databricks workspace
- Azure SQL Database
- Azure Key Vault for secrets
- Azure Monitor and Log Analytics

### 2. Data Factory Pipelines
- **Location**: `adf-pipelines/`
- Main orchestration pipeline
- Data quality validation pipeline
- Error handling and retry logic
- Parameterized configurations

### 3. Databricks Notebooks
- **Location**: `databricks-notebooks/`
- Data transformation logic
- Data quality checks using Great Expectations
- PII masking and data cleansing
- Schema validation and profiling

### 4. Monitoring & Alerting
- **Location**: `monitoring/`
- Azure Monitor dashboards
- Log Analytics queries
- Alert rules for pipeline failures

## Quick Start

1. **Deploy Infrastructure**:
   ```bash
   cd terraform
   terraform init
   terraform plan
   terraform apply
   ```

2. **Deploy Data Factory Pipelines**:
   ```bash
   cd ../scripts
   ./deploy-adf-pipelines.sh
   ```

3. **Deploy Databricks Notebooks**:
   ```bash
   ./deploy-databricks-notebooks.sh
   ```

## Security Features
- âœ… Managed Identities for authentication
- âœ… Azure Key Vault for secrets management
- âœ… Role-based access control (RBAC)
- âœ… Network security groups
- âœ… Data encryption at rest and in transit

## Data Quality Features
- âœ… Schema validation and profiling
- âœ… Duplicate detection and removal
- âœ… Null value handling
- âœ… Data type validation and casting
- âœ… PII detection and masking
- âœ… Business rule validation

## Monitoring Features
- âœ… Pipeline execution monitoring
- âœ… Data quality metrics
- âœ… Performance monitoring
- âœ… Cost tracking
- âœ… Automated alerting

## Prerequisites
- Azure CLI installed and configured
- Terraform >= 1.0
- Python 3.8+ (for local development)
- Azure subscription with appropriate permissions

## Cost Optimization
- Auto-scaling Databricks clusters
- Data Lake Storage lifecycle policies
- SQL Database elastic pools
- Scheduled pipeline execution

## Support
For questions or issues, please refer to the documentation in the `docs/` directory or create an issue in the repository.
# Azure-ETL-pipeline-solution-
